{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook to process benchmar results\n",
    "\n",
    "Please run this notebook after running all the benchmarks and storing them in the `results` dir. This will export them in the desired format for the single node benchmark plots of [qdrant.tech/benchmarks](https://qdrant.tech/benchmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-05T10:03:50.900734Z",
     "start_time": "2022-08-05T10:03:50.892651Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-05T10:03:50.982398Z",
     "start_time": "2022-08-05T10:03:50.903447Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = Path().resolve().parent / \"results\"\n",
    "DATA_DIR, list(DATA_DIR.glob(\"*.json\"))[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-05T10:03:51.482299Z",
     "start_time": "2022-08-05T10:03:51.477275Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "PATH_REGEX = re.compile(r\"(?P<engine_name>(\"\n",
    "                        r\"?P<engine>[a-z\\-]+)\"\n",
    "                        r\"\\-m\\-(?P<m>[0-9]+)\"\n",
    "                        r\"\\-ef\\-(?P<ef>[0-9]+)\"\n",
    "                        r\")\"\n",
    "                        r\"\\-(?P<dataset>[a-zA-Z0-9\\-]+)\"\n",
    "                        r\"\\-(?P<operation>(search)|(upload))\"\n",
    "                        r\"(\\-(?P<search_index>[0-9]{1,2})\\-)?\"\n",
    "                        r\"\\-?(?P<date>.*)\\.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-05T10:03:54.150582Z",
     "start_time": "2022-08-05T10:03:51.558766Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "upload_results, search_results = [], []\n",
    "\n",
    "for path in DATA_DIR.glob(\"*.json\"):\n",
    "    match = PATH_REGEX.match(path.name)\n",
    "    if match is None:\n",
    "        continue\n",
    "        \n",
    "    experiment = match.groupdict()\n",
    "\n",
    "    with open(path, \"r\") as fp:\n",
    "        stats = json.load(fp)\n",
    "        \n",
    "    params = stats['params']\n",
    "    dataset = params.pop(\"dataset\")\n",
    "    engine = params.pop(\"engine\")\n",
    "\n",
    "    entry = [engine, match[\"m\"], match[\"ef\"], \n",
    "             dataset, match[\"search_index\"], match[\"date\"], \n",
    "             params, stats[\"results\"]]\n",
    "    \n",
    "    if experiment[\"operation\"] == \"search\":\n",
    "        search_results.append(entry)\n",
    "    elif experiment[\"operation\"] == \"upload\":\n",
    "        upload_results.append(entry)\n",
    "\n",
    "len(upload_results), len(search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-05T10:03:54.157465Z",
     "start_time": "2022-08-05T10:03:54.153118Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "column_names = [\"engine\", \"m\", \"ef\", \"dataset\", \"search_index\", \"date\", \"params\", \"results\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_results, search_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-05T11:31:17.192306Z",
     "start_time": "2022-08-05T11:31:17.125766Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "upload_df = pd.DataFrame(upload_results, columns=column_names) \\\n",
    "    .drop(columns=\"search_index\")\n",
    "upload_df[\"date\"] = pd.to_datetime(upload_df[\"date\"], format=\"%Y-%m-%d-%H-%M-%S\")\n",
    "upload_df = upload_df.sort_values(\"date\", ascending=False) \\\n",
    "    .groupby([\"engine\", \"m\", \"ef\", \"dataset\"]) \\\n",
    "    .last()\n",
    "upload_df = pd.concat([upload_df, upload_df[\"results\"].apply(pd.Series)], axis=1)\n",
    "upload_df = upload_df.drop(columns=\"results\")\n",
    "\n",
    "print(len(upload_df))\n",
    "\n",
    "upload_df.sort_values(\"total_time\", ascending=True).head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-05T12:06:58.459530Z",
     "start_time": "2022-08-05T12:06:57.908842Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "search_df = pd.DataFrame(search_results, columns=column_names)\n",
    "search_df[\"date\"] = pd.to_datetime(search_df[\"date\"], format=\"%Y-%m-%d-%H-%M-%S\")\n",
    "search_df = search_df.sort_values(\"date\", ascending=False) \\\n",
    "    .groupby([\"engine\", \"m\", \"ef\", \"dataset\", \"search_index\"]) \\\n",
    "    .first()\n",
    "\n",
    "print(len(search_df))\n",
    "\n",
    "for column_name in [\"params\", \"results\"]:\n",
    "    search_df = pd.concat([search_df, search_df[column_name].apply(pd.Series)], axis=1)\n",
    "    search_df = search_df.drop(columns=column_name)\n",
    "search_df.sort_values(\"rps\", ascending=False).head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_search = search_df.reset_index()\n",
    "_upload = upload_df.reset_index()\n",
    "\n",
    "joined_df = _search.merge(_upload, on=[\"engine\", \"m\", \"ef\", \"dataset\"], how=\"left\", suffixes=(\"_search\", \"_upload\"))\n",
    "print(len(joined_df))\n",
    "joined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)  \n",
    "\n",
    "joined_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_results = []\n",
    "\n",
    "for index, row in joined_df.reset_index().iterrows():\n",
    "    engine_params = {}\n",
    "    if isinstance(row['params'], dict):\n",
    "        engine_params.update(row['params'])\n",
    "    if isinstance(row['config'], dict): # Search config\n",
    "        engine_params.update(row['config'])\n",
    "\n",
    "    engine_name = row['engine']\n",
    "\n",
    "    if engine_name == \"qdrant-rps\" or engine_name == \"qdrant-bq-rps\" or engine_name == \"qdrant-sq-rps\":\n",
    "        engine_name = \"qdrant\"\n",
    "\n",
    "    json_object = {\n",
    "        \"engine_name\": engine_name,\n",
    "        \"setup_name\": f\"{row['engine']}-m-{row['m']}-ef-{row['ef']}\",\n",
    "        \"dataset_name\": row['dataset'],\n",
    "        # \"search_idx\": row['search_index'],\n",
    "        \"upload_time\": row['upload_time'],\n",
    "        \"total_upload_time\": row['total_time_upload'],\n",
    "        \"p95_time\": row['p95_time'],\n",
    "        \"rps\": row['rps'],\n",
    "        \"parallel\": row['parallel'],\n",
    "        \"p99_time\": row['p99_time'],\n",
    "        \"mean_time\": row['mean_time'],\n",
    "        \"mean_precisions\": row['mean_precisions'],\n",
    "        \"engine_params\": engine_params,\n",
    "    }\n",
    "    json_results.append(json_object)\n",
    "    \n",
    "    parallel = row['parallel']\n",
    "\n",
    "\n",
    "format = '%Y-%M-%dT%H:%M:%S'\n",
    "now = datetime.now().replace(tzinfo=timezone.utc).strftime(format)\n",
    "\n",
    "Path(f\"results.json\").write_text(json.dumps(json_results, indent=2))\n",
    "Path(f\"results-{now}.json\").write_text(json.dumps(json_results, indent=2))\n",
    "\n",
    "json_results[-1], len(json_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
